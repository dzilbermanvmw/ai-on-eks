apiVersion: nvidia.com/v1
kind: ClusterPolicy
metadata:
  annotations:
    meta.helm.sh/release-name: gpu-operator-1763061387
    meta.helm.sh/release-namespace: gpu-operator
  creationTimestamp: "2025-11-13T19:16:34Z"
  generation: 2
  labels:
    app.kubernetes.io/component: gpu-operator
    app.kubernetes.io/instance: gpu-operator-1763061387
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gpu-operator
    app.kubernetes.io/version: v25.10.0
    helm.sh/chart: gpu-operator-v25.10.0
  name: cluster-policy
  resourceVersion: "19409133"
  uid: f0ed7bfc-dff4-474c-bcad-d5a08d7a4e37
spec:
  ccManager:
    defaultMode: "off"
    enabled: false
    env: []
    image: k8s-cc-manager
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: v0.1.1
  cdi:
    default: false
    enabled: true
  daemonsets:
    labels:
      app.kubernetes.io/managed-by: gpu-operator
      helm.sh/chart: gpu-operator-v25.10.0
    priorityClassName: system-node-critical
    rollingUpdate:
      maxUnavailable: "1"
    tolerations:
    - effect: NoSchedule
      key: nvidia.com/gpu
      operator: Exists
    updateStrategy: RollingUpdate
  dcgm:
    enabled: false
    image: dcgm
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: 4.4.1-2-ubuntu22.04
  dcgmExporter:
    enabled: true
    image: dcgm-exporter
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/k8s
    service:
      internalTrafficPolicy: Cluster
    serviceMonitor:
      additionalLabels: {}
      enabled: false
      honorLabels: false
      interval: 15s
      relabelings: []
    version: 4.4.1-4.6.0-distroless
  devicePlugin:
    enabled: true
    image: k8s-device-plugin
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia
    version: v0.18.0
  driver:
    certConfig:
      name: ""
    enabled: true
    image: driver
    imagePullPolicy: IfNotPresent
    kernelModuleConfig:
      name: ""
    kernelModuleType: auto
    licensingConfig:
      nlsEnabled: true
      secretName: ""
    manager:
      image: k8s-driver-manager
      imagePullPolicy: IfNotPresent
      repository: nvcr.io/nvidia/cloud-native
      version: v0.9.0
    rdma:
      enabled: false
      useHostMofed: false
    repoConfig:
      configMapName: ""
    repository: nvcr.io/nvidia
    startupProbe:
      failureThreshold: 120
      initialDelaySeconds: 60
      periodSeconds: 10
      timeoutSeconds: 60
    upgradePolicy:
      autoUpgrade: true
      drain:
        deleteEmptyDir: false
        enable: false
        force: false
        timeoutSeconds: 300
      maxParallelUpgrades: 1
      maxUnavailable: 25%
      podDeletion:
        deleteEmptyDir: false
        force: false
        timeoutSeconds: 300
      waitForCompletion:
        timeoutSeconds: 0
    useNvidiaDriverCRD: false
    usePrecompiled: false
    version: 580.95.05
    virtualTopology:
      config: ""
  gdrcopy:
    enabled: false
    image: gdrdrv
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: v2.5.1
  gds:
    enabled: false
    image: nvidia-fs
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: 2.26.6
  gfd:
    enabled: true
    image: k8s-device-plugin
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia
    version: v0.18.0
  hostPaths:
    driverInstallDir: /run/nvidia/driver
    rootFS: /
  kataManager:
    config:
      artifactsDir: /opt/nvidia-gpu-operator/artifacts/runtimeclasses
      runtimeClasses:
      - artifacts:
          pullSecret: ""
          url: nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03
        name: kata-nvidia-gpu
        nodeSelector: {}
      - artifacts:
          pullSecret: ""
          url: nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp
        name: kata-nvidia-gpu-snp
        nodeSelector:
          nvidia.com/cc.capable: "true"
    enabled: false
    image: k8s-kata-manager
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: v0.2.3
  mig:
    strategy: single
  migManager:
    config:
      default: all-disabled
      name: default-mig-parted-config
    enabled: true
    gpuClientsConfig:
      name: ""
    image: k8s-mig-manager
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: v0.13.0
  nodeStatusExporter:
    enabled: false
    image: gpu-operator
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia
    version: v25.10.0
  operator:
    defaultRuntime: docker
    initContainer:
      image: cuda
      imagePullPolicy: IfNotPresent
      repository: nvcr.io/nvidia
      version: 13.0.1-base-ubi9
    runtimeClass: nvidia
  psa:
    enabled: false
  sandboxDevicePlugin:
    enabled: true
    image: kubevirt-gpu-device-plugin
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia
    version: v1.4.0
  sandboxWorkloads:
    defaultWorkload: container
    enabled: false
  toolkit:
    enabled: true
    image: container-toolkit
    imagePullPolicy: IfNotPresent
    installDir: /opt/nvidia
    repository: nvcr.io/nvidia/k8s
    version: v1.18.0
  validator:
    image: gpu-operator
    imagePullPolicy: IfNotPresent
    plugin:
      env: []
    repository: nvcr.io/nvidia
    version: v25.10.0
  vfioManager:
    driverManager:
      image: k8s-driver-manager
      imagePullPolicy: IfNotPresent
      repository: nvcr.io/nvidia/cloud-native
      version: v0.9.0
    enabled: true
    image: cuda
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia
    version: 13.0.1-base-ubi9
  vgpuDeviceManager:
    config:
      default: default
      name: ""
    enabled: true
    image: vgpu-device-manager
    imagePullPolicy: IfNotPresent
    repository: nvcr.io/nvidia/cloud-native
    version: v0.4.1
  vgpuManager:
    driverManager:
      image: k8s-driver-manager
      imagePullPolicy: IfNotPresent
      repository: nvcr.io/nvidia/cloud-native
      version: v0.9.0
    enabled: false
    image: vgpu-manager
    imagePullPolicy: IfNotPresent
status:
  conditions:
  - lastTransitionTime: "2025-11-13T19:16:53Z"
    message: No GPU node found, watching for new nodes to join the cluster.
    reason: NoGPUNodes
    status: "True"
    type: Ready
  - lastTransitionTime: "2025-11-13T19:16:53Z"
    message: ""
    reason: Ready
    status: "False"
    type: Error
  namespace: gpu-operator
  state: ready
